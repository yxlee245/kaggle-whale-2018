{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN Model (Single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from src.sampler import train_test_bootstrapper\n",
    "from src.model_api import getSimpleModel\n",
    "from src.prediction import array_filter, array_to_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_train: (25361, 224, 224, 3)\n",
      "Length of labels_train: 25361\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_train.pickle', 'rb') as file:\n",
    "    data_train = pickle.load(file)\n",
    "with open('data/derived/labels_train.pickle', 'rb') as file:\n",
    "    labels_train = pickle.load(file)\n",
    "print('Shape of data_train:', data_train.shape)\n",
    "print('Length of labels_train:', len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_test: (7960, 224, 224, 3)\n",
      "Length of filename_test: 7960\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_test.pickle', 'rb') as file:\n",
    "    data_test = pickle.load(file)\n",
    "with open('data/derived/test_file_names.pickle', 'rb') as file:\n",
    "    filenames_test = pickle.load(file)\n",
    "print('Shape of data_test:', data_test.shape)\n",
    "print('Length of filename_test:', len(filenames_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to integers for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['w_025911c', 'new_whale', 'new_whale', 'new_whale', 'new_whale']\n",
      "Encoded labels: [44  0  0  0  0]\n",
      "Label encoder classes: ['new_whale' 'w_0003639' 'w_0003c59' 'w_0027efa' 'w_00289b1']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "print('Original labels: {}'.format(labels_train[:5]))\n",
    "print('Encoded labels: {}'.format(labels_train_encoded[:5]))\n",
    "print('Label encoder classes: {}'.format(label_encoder.classes_[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sample size and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 25361\n",
      "Number of clases: 5005\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(labels_train_encoded)\n",
    "num_classes = len(set(labels_train_encoded))\n",
    "print('Sample size:', sample_size)\n",
    "print('Number of clases:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Single CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple CNN model (Random Seed = 2019, assuming class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data_train\n",
    "data_train = data_train / 255\n",
    "data_train = data_train.astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'models/weights-{epoch:02d}-{val_loss:.3f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')\n",
    "\n",
    "model = getSimpleModel(num_classes=len(set(labels_train_encoded)), resize_width=224)\n",
    "\n",
    "batch_size = 32\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=.1,\n",
    "                               height_shift_range=.1,\n",
    "                               shear_range=0.5,\n",
    "                               zoom_range=(0.9, 1.1),\n",
    "                               fill_mode='constant',\n",
    "                               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2536/2536 [==============================] - 756s 298ms/step - loss: 7.1958 - acc: 0.1835 - val_loss: 4.6493 - val_acc: 0.5763\n",
      "Epoch 2/10\n",
      "2536/2536 [==============================] - 751s 296ms/step - loss: 6.9585 - acc: 0.1848 - val_loss: 4.8778 - val_acc: 0.5763\n",
      "Epoch 3/10\n",
      "2536/2536 [==============================] - 752s 297ms/step - loss: 6.5814 - acc: 0.1834 - val_loss: 4.9661 - val_acc: 0.5762\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_bootstrapper(data_train, labels_train_encoded,\n",
    "                                                           bootstrapper_size=sample_size,\n",
    "                                                           class_imbalance=True, random_state=2019)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "image_generator_samples = image_gen.flow(X_train, y_train, batch_size=batch_size, seed=2019)\n",
    "    \n",
    "np.random.seed(2019)\n",
    "set_random_seed(2019)\n",
    "train_size, epochs = X_train.shape[0], 10\n",
    "model.fit_generator(image_generator_samples, steps_per_epoch=train_size//epochs, \n",
    "                    validation_data=(X_test, y_test), epochs=epochs, shuffle=True,\n",
    "                    callbacks=[checkpoint, early_stop])\n",
    "\n",
    "model.save_weights('models/weights_CNN_single.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getSimpleModel(num_classes=len(set(labels_train_encoded)), resize_width=224)\n",
    "model.load_weights('models/weights_CNN_single.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_test = data_test / 255\n",
    "data_test = data_test.astype(dtype=np.float32)\n",
    "preds = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain labels with top 5 softmax values for each array row and concatenate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_indices = np.apply_along_axis(array_filter, arr=preds, axis=1, n_top=5, labels=label_encoder.classes_)\n",
    "predictions_array = np.apply_along_axis(array_to_string, arr=top5_indices, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission DataFrame and export as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  c303faac6.jpg  new_whale w_eee296c w_1834b49 w_e13f4e8 w_9d29561\n",
      "1  96c2b7290.jpg  new_whale w_60ce6fc w_6822dbc w_c6b4d61 w_af367c3\n",
      "2  69f6cd44f.jpg  new_whale w_d405854 w_2b069ba w_04003e9 w_1ca9ab1\n",
      "3  a965dea33.jpg  new_whale w_8da30ad w_343f088 w_a9304b9 w_8ea9f68\n",
      "4  9a225e056.jpg  new_whale w_789c969 w_343f088 w_99e43ae w_fdcaaa8\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'Image': filenames_test, 'Id': predictions_array})\n",
    "submission_df.to_csv('submission_v3.csv', index=False)\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
