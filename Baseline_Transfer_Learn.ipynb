{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from src.sampler import class_weighter, train_test_bootstrapper\n",
    "from src.model_api import getPretrainedModel\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_train: (25361, 224, 224, 3)\n",
      "Length of labels_train: 25361\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_train.pickle', 'rb') as file:\n",
    "    data_train = pickle.load(file)\n",
    "with open('data/derived/labels_train.pickle', 'rb') as file:\n",
    "    labels_train = pickle.load(file)\n",
    "print('Shape of data_train:', data_train.shape)\n",
    "print('Length of labels_train:', len(labels_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to integers for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['w_025911c', 'new_whale', 'new_whale', 'new_whale', 'new_whale']\n",
      "Encoded labels: [44  0  0  0  0]\n",
      "Label encoder classes: ['new_whale' 'w_0003639' 'w_0003c59' 'w_0027efa' 'w_00289b1']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "print('Original labels: {}'.format(labels_train[:5]))\n",
    "print('Encoded labels: {}'.format(labels_train_encoded[:5]))\n",
    "print('Label encoder classes: {}'.format(label_encoder.classes_[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clases: 5005\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(labels_train_encoded))\n",
    "print('Number of clases:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.760761589403974e-05 0.75 0.75\n"
     ]
    }
   ],
   "source": [
    "class_weight_dict = class_weighter(labels_train_encoded)\n",
    "print(class_weight_dict[0], class_weight_dict[1], class_weight_dict[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine performance of pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'models/weights-resnet50-{epoch:02d}-{val_loss:.3f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')\n",
    "\n",
    "model_resnet50 = getPretrainedModel(ResNet50(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                   num_classes=len(set(labels_train_encoded)),\n",
    "                                   num_layers_freeze=0)\n",
    "\n",
    "batch_size = 32\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=.1,\n",
    "                               height_shift_range=.1,\n",
    "                               shear_range=0.5,\n",
    "                               zoom_range=(0.9, 1.1),\n",
    "                               fill_mode='constant',\n",
    "                               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 98s 492ms/step - loss: 7.0113 - acc: 0.1881 - val_loss: 6.3461 - val_acc: 0.3963\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 96s 478ms/step - loss: 6.9311 - acc: 0.1939 - val_loss: 6.3015 - val_acc: 0.3963\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 97s 485ms/step - loss: 6.9112 - acc: 0.1892 - val_loss: 6.2613 - val_acc: 0.3963\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 96s 481ms/step - loss: 6.8717 - acc: 0.1894 - val_loss: 6.2252 - val_acc: 0.3963\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 96s 479ms/step - loss: 6.8280 - acc: 0.1905 - val_loss: 6.1927 - val_acc: 0.3963\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 97s 485ms/step - loss: 6.7904 - acc: 0.1911 - val_loss: 6.1650 - val_acc: 0.3963\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 96s 478ms/step - loss: 6.7629 - acc: 0.1905 - val_loss: 6.1421 - val_acc: 0.3963\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 95s 477ms/step - loss: 6.7256 - acc: 0.1920 - val_loss: 6.1236 - val_acc: 0.3963\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 95s 477ms/step - loss: 6.7102 - acc: 0.1895 - val_loss: 6.1104 - val_acc: 0.3963\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 95s 477ms/step - loss: 6.6951 - acc: 0.1889 - val_loss: 6.1021 - val_acc: 0.3963\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 98s 491ms/step - loss: 6.9118 - acc: 0.2042 - val_loss: 6.0746 - val_acc: 0.3946\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 95s 477ms/step - loss: 6.9022 - acc: 0.2003 - val_loss: 6.0693 - val_acc: 0.3946\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 95s 477ms/step - loss: 6.8309 - acc: 0.2062 - val_loss: 6.0661 - val_acc: 0.3946\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 96s 480ms/step - loss: 6.8151 - acc: 0.2055 - val_loss: 6.0669 - val_acc: 0.3946\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 96s 480ms/step - loss: 6.7888 - acc: 0.2047 - val_loss: 6.0702 - val_acc: 0.3946\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 99s 495ms/step - loss: 7.6574 - acc: 0.1955 - val_loss: 6.0011 - val_acc: 0.3955\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 96s 481ms/step - loss: 7.5795 - acc: 0.1992 - val_loss: 6.0046 - val_acc: 0.3955\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 96s 481ms/step - loss: 7.5626 - acc: 0.1981 - val_loss: 6.0083 - val_acc: 0.3955\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 100s 498ms/step - loss: 7.4832 - acc: 0.2130 - val_loss: 6.0101 - val_acc: 0.3944\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 96s 478ms/step - loss: 7.4611 - acc: 0.2106 - val_loss: 6.0108 - val_acc: 0.3944\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 95s 477ms/step - loss: 7.4158 - acc: 0.2122 - val_loss: 6.0124 - val_acc: 0.3944\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 100s 498ms/step - loss: 7.6930 - acc: 0.1928 - val_loss: 5.9977 - val_acc: 0.3957\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 96s 482ms/step - loss: 7.6715 - acc: 0.1919 - val_loss: 6.0050 - val_acc: 0.3957\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 96s 479ms/step - loss: 7.6388 - acc: 0.1897 - val_loss: 6.0130 - val_acc: 0.3957\n"
     ]
    }
   ],
   "source": [
    "val_acc_list = []\n",
    "for loop_no in range(5):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_bootstrapper(data_train, labels_train_encoded,\n",
    "                                                               bootstrapper_size=2000,\n",
    "                                                               random_state=2018+loop_no)\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "    image_generator_samples = image_gen.flow(X_train,\n",
    "                                         y_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         seed=2018+loop_no)\n",
    "    np.random.seed(2018+loop_no)\n",
    "    set_random_seed(2018+loop_no)\n",
    "    train_size, epochs = X_train.shape[0], 10\n",
    "    hist = model_resnet50.fit_generator(image_generator_samples,\n",
    "                                        steps_per_epoch=train_size//epochs,\n",
    "                                        validation_data=(X_test, y_test),\n",
    "                                        epochs=epochs,\n",
    "                                        shuffle=True,\n",
    "                                        callbacks=[checkpoint, early_stop])\n",
    "    val_acc_list.append(max(hist.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of accuracy scores: 0.39530605764757765\n",
      "SD of accuracy scores: 0.0007033052258070625\n"
     ]
    }
   ],
   "source": [
    "print('Mean of accuracy scores:', np.mean(val_acc_list))\n",
    "print('SD of accuracy scores:', np.std(val_acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
