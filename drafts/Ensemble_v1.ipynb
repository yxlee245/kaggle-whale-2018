{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble of 8 different CNN models, average weighted by Kaggle LB score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pickle, os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from src.sampler import sample_weighter\n",
    "from src.model_api import (getSimpleModel, getSimpleModelV2, getSimpleModelV3, getSimpleModelV4,\n",
    "                           getSimpleModelV5, getSimpleModelV6, getSimpleModelV7, getSimpleModelV8)\n",
    "from src.prediction import array_filter, array_to_string\n",
    "from src.custom_metric import as_keras_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_train: (25361, 100, 100, 3)\n",
      "Length of labels_train: 25361\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_train.pickle', 'rb') as file:\n",
    "    data_train = pickle.load(file)\n",
    "with open('data/derived/labels_train.pickle', 'rb') as file:\n",
    "    labels_train = pickle.load(file)\n",
    "print('Shape of data_train:', data_train.shape)\n",
    "print('Length of labels_train:', len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_test: (7960, 100, 100, 3)\n",
      "Length of filename_test: 7960\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_test.pickle', 'rb') as file:\n",
    "    data_test = pickle.load(file)\n",
    "with open('data/derived/test_file_names.pickle', 'rb') as file:\n",
    "    filenames_test = pickle.load(file)\n",
    "print('Shape of data_test:', data_test.shape)\n",
    "print('Length of filename_test:', len(filenames_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to integers for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['new_whale', 'new_whale', 'w_75d0e61', 'w_396c12b', 'w_d8de44c']\n",
      "Encoded labels: [   0    0 2308 1134 4209]\n",
      "Label encoder classes: ['new_whale' 'w_0003639' 'w_0003c59' 'w_0027efa' 'w_00289b1']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "print('Original labels: {}'.format(labels_train[:5]))\n",
    "print('Encoded labels: {}'.format(labels_train_encoded[:5]))\n",
    "print('Label encoder classes: {}'.format(label_encoder.classes_[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sample size and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 25361\n",
      "Number of clases: 5005\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(labels_train_encoded)\n",
    "num_classes = len(set(labels_train_encoded))\n",
    "print('Sample size:', sample_size)\n",
    "print('Number of clases:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create metrics and load base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create precision and recall metrics\n",
    "# Note: top_k_categorical_accuracy function in keras.metrics has default k value of 5\n",
    "top_5_categorical_accuracy = keras.metrics.top_k_categorical_accuracy\n",
    "f1_score = as_keras_metric(tf.contrib.metrics.f1_score)\n",
    "metric_list = [top_5_categorical_accuracy, f1_score]\n",
    "\n",
    "model1 = getSimpleModel(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model1.load_weights('models/weights-model1-final.hdf5')\n",
    "model2 = getSimpleModelV2(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model2.load_weights('models/weights-model2-final.hdf5')\n",
    "model3 = getSimpleModelV3(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model3.load_weights('models/weights-model3-final.hdf5')\n",
    "model4 = getSimpleModelV4(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model4.load_weights('models/weights-model4-final.hdf5')\n",
    "model5 = getSimpleModelV5(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model5.load_weights('models/weights-model5-final.hdf5')\n",
    "model6 = getSimpleModelV6(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model6.load_weights('models/weights-model6-final.hdf5')\n",
    "model7 = getSimpleModelV7(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model7.load_weights('models/weights-model7-final.hdf5')\n",
    "model8 = getSimpleModelV8(num_classes=num_classes, resize_width=100, metric_list=metric_list)\n",
    "model8.load_weights('models/weights-model8-final.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain predictions from base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_norm = (data_test / 255).astype(np.float32)\n",
    "\n",
    "pred1 = model1.predict(data_test_norm)\n",
    "pred2 = model2.predict(data_test_norm)\n",
    "pred3 = model3.predict(data_test_norm)\n",
    "pred4 = model4.predict(data_test_norm)\n",
    "pred5 = model5.predict(data_test_norm)\n",
    "pred6 = model6.predict(data_test_norm)\n",
    "pred7 = model7.predict(data_test_norm)\n",
    "pred8 = model8.predict(data_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute weighted average of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_preds = 0.207 ** 2 * pred1 + 0.307 ** 2 * pred2 + 0.302 ** 2 * pred3 + 0.315 ** 2 * pred4 +\\\n",
    "0.285 ** 2 * pred5 + 0.334 ** 2 * pred6 + 0.301 ** 2 * pred7 + 0.329 ** 2 * pred8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain labels with top 5 softmax values for each array row and concatenate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_indices = np.apply_along_axis(array_filter, arr=average_preds, axis=1, n_top=5, labels=label_encoder.classes_)\n",
    "predictions_array = np.apply_along_axis(array_to_string, arr=top5_indices, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission DataFrame and export as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  660352b03.jpg  new_whale w_af367c3 w_8dc6c05 w_9b565fa w_b9c99cc\n",
      "1  bec66f23c.jpg  new_whale w_bbfce38 w_c0d11da w_9c506f6 w_e906edd\n",
      "2  fb8c2c146.jpg  new_whale w_a4ac5dd w_bf960fa w_dba1c08 w_16def42\n",
      "3  0ff9cd790.jpg  new_whale w_34120de w_71b9a85 w_3815890 w_584e1dc\n",
      "4  861e6c332.jpg  new_whale w_8c25681 w_6822dbc w_4f9c015 w_564a34b\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'Image': filenames_test, 'Id': predictions_array})\n",
    "submission_df.to_csv('data/derived/submission_ensemble_1.csv', index=False)\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
