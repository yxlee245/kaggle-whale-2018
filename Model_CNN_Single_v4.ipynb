{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN Model v4 (Single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single model (simpler one) trained on subsampled training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from src.sampler import train_test_bootstrapper, train_test_bootstrapper_v2, undersampler\n",
    "from src.model_api import getSimpleModel\n",
    "from src.prediction import array_filter, array_to_string\n",
    "from src.custom_metric import as_keras_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_train: (15697, 128, 128, 3)\n",
      "Length of labels_train: 15697\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_train_v3.pickle', 'rb') as file:\n",
    "    data_train = pickle.load(file)\n",
    "with open('data/derived/labels_train_v3.pickle', 'rb') as file:\n",
    "    labels_train = pickle.load(file)\n",
    "print('Shape of data_train:', data_train.shape)\n",
    "print('Length of labels_train:', len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_test: (7960, 128, 128, 3)\n",
      "Length of filename_test: 7960\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_test_v2.pickle', 'rb') as file:\n",
    "    data_test = pickle.load(file)\n",
    "with open('data/derived/test_file_names.pickle', 'rb') as file:\n",
    "    filenames_test = pickle.load(file)\n",
    "print('Shape of data_test:', data_test.shape)\n",
    "print('Length of filename_test:', len(filenames_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to integers for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['w_f48451c', 'w_c3d896a', 'w_20df2c5', 'w_dd88965', 'w_64404ac']\n",
      "Encoded labels: [4785 3807  661 4314 1928]\n",
      "Label encoder classes: ['w_0003639' 'w_0003c59' 'w_0027efa' 'w_00289b1' 'w_002c810']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "print('Original labels: {}'.format(labels_train[:5]))\n",
    "print('Encoded labels: {}'.format(labels_train_encoded[:5]))\n",
    "print('Label encoder classes: {}'.format(label_encoder.classes_[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sample size and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 15697\n",
      "Number of clases: 5004\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(labels_train_encoded)\n",
    "num_classes = len(set(labels_train_encoded))\n",
    "print('Sample size:', sample_size)\n",
    "print('Number of clases:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Single CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple CNN model (Random Seed = 2019, assuming class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (15697, 128, 128, 3)\n",
      "Shape of X_validation: (5913, 128, 128, 3)\n",
      "Shape of y_train: (15697, 5004)\n",
      "Shape of y_validation: (5913, 5004)\n"
     ]
    }
   ],
   "source": [
    "#sample_index, validation_index = undersampler(labels_array=labels_train_encoded, validation_size=5000, random_state=2019)\n",
    "\n",
    "#X_train = data_train[sample_index] / 255\n",
    "#X_validation = data_train[validation_index] / 255\n",
    "#y_train = labels_train_encoded[sample_index]\n",
    "#y_validation = labels_train_encoded[validation_index]\n",
    "\n",
    "data_train_norm = data_train / 255\n",
    "X_train, X_validation, y_train, y_validation = train_test_bootstrapper(data_train_norm, labels_train_encoded,\n",
    "                                                                          bootstrapper_size=sample_size,\n",
    "                                                                          class_imbalance=True, random_state=2019)\n",
    "\n",
    "#X_train, X_validation, y_train, y_validation = train_test_split(data_train_norm, labels_train_encoded, test_size=0.2,\n",
    "#                                                                random_state=2019)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_validation = to_categorical(y_validation, num_classes=num_classes)\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_validation:', X_validation.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of y_validation:', y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'models/weights-{epoch:02d}-{val_loss:.3f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss', restore_best_weights=True)\n",
    "\n",
    "# Create precision and recall metrics\n",
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)\n",
    "metric_list = ['accuracy', precision, recall]\n",
    "\n",
    "model = getSimpleModel(num_classes=num_classes, resize_width=128, metric_list=metric_list)\n",
    "\n",
    "batch_size = 32\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=.1,\n",
    "                               height_shift_range=.1,\n",
    "                               shear_range=0.5,\n",
    "                               zoom_range=(0.9, 1.1),\n",
    "                               fill_mode='constant',\n",
    "                               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3139/3139 [==============================] - 314s 100ms/step - loss: 7.7511 - acc: 0.0047 - precision: 1.9978e-04 - recall: 0.9997 - val_loss: 9.2070 - val_acc: 0.0120 - val_precision: 1.9984e-04 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "3139/3139 [==============================] - 313s 100ms/step - loss: 6.4240 - acc: 0.0197 - precision: 1.9983e-04 - recall: 1.0000 - val_loss: 9.9543 - val_acc: 0.0093 - val_precision: 1.9984e-04 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "3139/3139 [==============================] - 313s 100ms/step - loss: 5.6615 - acc: 0.0456 - precision: 1.9987e-04 - recall: 1.0000 - val_loss: 10.2646 - val_acc: 0.0086 - val_precision: 1.9996e-04 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "image_generator_samples = image_gen.flow(X_train, y_train, batch_size=batch_size, seed=2019)\n",
    "\n",
    "np.random.seed(2019)\n",
    "set_random_seed(2019)\n",
    "train_size, epochs = X_train.shape[0], 10\n",
    "model.fit_generator(image_generator_samples, steps_per_epoch=2*train_size//epochs, \n",
    "                    validation_data=(X_validation, y_validation), epochs=epochs, shuffle=True,\n",
    "                    callbacks=[checkpoint, early_stop])\n",
    "\n",
    "model.save_weights('models/weights_CNN_single_v4.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getSimpleModel(num_classes=num_classes, resize_width=128, metric_list=metric_list)\n",
    "model.load_weights('models/weights_CNN_single_v4.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_norm = data_test / 255\n",
    "preds = model.predict(data_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain labels with top 5 softmax values for each array row and concatenate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_indices = np.apply_along_axis(array_filter, arr=preds, axis=1, n_top=5, labels=label_encoder.classes_, threshold=0.01)\n",
    "predictions_array = np.apply_along_axis(array_to_string, arr=top5_indices, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission DataFrame and export as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  c303faac6.jpg  w_23a388d w_6e209a8 w_88e4537 w_9b5109b w_5e8e218\n",
      "1  96c2b7290.jpg  w_88e4537 w_23a388d w_5e8e218 w_60ce6fc w_6cda039\n",
      "2  69f6cd44f.jpg  w_5773c71 w_7c27fbd w_aabdf8c w_e2a09d4 new_whale\n",
      "3  a965dea33.jpg  w_a9304b9 w_d72771c w_1f0cf0a w_8da30ad new_whale\n",
      "4  9a225e056.jpg  w_789c969 w_3de579a w_9b5109b w_a9304b9 new_whale\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'Image': filenames_test, 'Id': predictions_array})\n",
    "submission_df.to_csv('submission_v5.csv', index=False)\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.0053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
