{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning using DenseNet201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import set_random_seed\n",
    "#from keras.applications.resnet50 import ResNet50, preprocess_input as resnet50_preprocess\n",
    "from keras.applications.densenet import DenseNet201, preprocess_input as densenet201_preprocess\n",
    "#from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "#from keras.applications.nasnet import NASNetMobile\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from src.sampler import train_test_bootstrapper\n",
    "from src.model_api import getPretrainedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_train: (25361, 224, 224, 3)\n",
      "Length of labels_train: 25361\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/data_train.pickle', 'rb') as file:\n",
    "    data_train = pickle.load(file)\n",
    "with open('data/derived/labels_train.pickle', 'rb') as file:\n",
    "    labels_train = pickle.load(file)\n",
    "print('Shape of data_train:', data_train.shape)\n",
    "print('Length of labels_train:', len(labels_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to integers for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['w_025911c', 'new_whale', 'new_whale', 'new_whale', 'new_whale']\n",
      "Encoded labels: [44  0  0  0  0]\n",
      "Label encoder classes: ['new_whale' 'w_0003639' 'w_0003c59' 'w_0027efa' 'w_00289b1']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "print('Original labels: {}'.format(labels_train[:5]))\n",
    "print('Encoded labels: {}'.format(labels_train_encoded[:5]))\n",
    "print('Label encoder classes: {}'.format(label_encoder.classes_[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sample size and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 25361\n",
      "Number of clases: 5005\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(labels_train_encoded)\n",
    "num_classes = len(set(labels_train_encoded))\n",
    "print('Sample size:', sample_size)\n",
    "print('Number of clases:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DenseNet201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet Model 1 (Random Seed = 1, assuming no class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'models/weights-{epoch:02d}-{val_loss:.3f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')\n",
    "\n",
    "model = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                       num_classes=len(set(labels_train_encoded)),\n",
    "                                       percent_layers_freeze=0.1)\n",
    "\n",
    "batch_size = 32\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=.1,\n",
    "                               height_shift_range=.1,\n",
    "                               shear_range=0.5,\n",
    "                               zoom_range=(0.9, 1.1),\n",
    "                               fill_mode='constant',\n",
    "                               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5072/5072 [==============================] - 1602s 316ms/step - loss: 5.7216 - acc: 0.3819 - val_loss: 6.3653 - val_acc: 0.3831\n",
      "Epoch 2/10\n",
      "5072/5072 [==============================] - 1572s 310ms/step - loss: 5.0150 - acc: 0.3820 - val_loss: 6.2866 - val_acc: 0.3835\n",
      "Epoch 3/10\n",
      "5072/5072 [==============================] - 1566s 309ms/step - loss: 4.7255 - acc: 0.3836 - val_loss: 6.4515 - val_acc: 0.3841\n",
      "Epoch 4/10\n",
      "5072/5072 [==============================] - 1573s 310ms/step - loss: 4.6083 - acc: 0.3861 - val_loss: 6.5239 - val_acc: 0.3847\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_bootstrapper(data_train, labels_train_encoded,\n",
    "                                                           bootstrapper_size=sample_size,\n",
    "                                                           class_imbalance=False, random_state=1)\n",
    "    \n",
    "X_train = densenet201_preprocess(X_train)\n",
    "X_test = densenet201_preprocess(X_test)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "image_generator_samples = image_gen.flow(X_train, y_train, batch_size=batch_size, seed=1)\n",
    "    \n",
    "np.random.seed(1)\n",
    "set_random_seed(1)\n",
    "train_size, epochs = X_train.shape[0], 10\n",
    "hist = model.fit_generator(image_generator_samples, steps_per_epoch=2*train_size//epochs,\n",
    "                           validation_data=(X_test, y_test), epochs=epochs, shuffle=True,\n",
    "                           callbacks=[checkpoint, early_stop])\n",
    "\n",
    "model.save_weights('models/weights_densenet201_1.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet Model 2 (Random Seed = 2, assuming no class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'models/weights-{epoch:02d}-{val_loss:.3f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')\n",
    "\n",
    "model = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                           num_classes=len(set(labels_train_encoded)),\n",
    "                           percent_layers_freeze=0.1)\n",
    "\n",
    "batch_size = 32\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=.1,\n",
    "                               height_shift_range=.1,\n",
    "                               shear_range=0.5,\n",
    "                               zoom_range=(0.9, 1.1),\n",
    "                               fill_mode='constant',\n",
    "                               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5072/5072 [==============================] - 1579s 311ms/step - loss: 5.6498 - acc: 0.3828 - val_loss: 6.4239 - val_acc: 0.3775\n",
      "Epoch 2/10\n",
      "5072/5072 [==============================] - 1579s 311ms/step - loss: 4.9054 - acc: 0.3845 - val_loss: 6.1716 - val_acc: 0.3780\n",
      "Epoch 3/10\n",
      "5072/5072 [==============================] - 1581s 312ms/step - loss: 4.6185 - acc: 0.3863 - val_loss: 6.5170 - val_acc: 0.3807\n",
      "Epoch 4/10\n",
      "5072/5072 [==============================] - 1573s 310ms/step - loss: 4.5008 - acc: 0.3881 - val_loss: 6.1504 - val_acc: 0.3793\n",
      "Epoch 5/10\n",
      "5072/5072 [==============================] - 1580s 312ms/step - loss: 4.4308 - acc: 0.3892 - val_loss: 6.2744 - val_acc: 0.3816\n",
      "Epoch 6/10\n",
      "5072/5072 [==============================] - 1568s 309ms/step - loss: 4.3865 - acc: 0.3901 - val_loss: 6.1912 - val_acc: 0.3826\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_bootstrapper(data_train, labels_train_encoded,\n",
    "                                                           bootstrapper_size=sample_size,\n",
    "                                                           class_imbalance=False, random_state=2)\n",
    "    \n",
    "X_train = densenet201_preprocess(X_train)\n",
    "X_test = densenet201_preprocess(X_test)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "image_generator_samples = image_gen.flow(X_train, y_train, batch_size=batch_size, seed=2)\n",
    "    \n",
    "np.random.seed(2)\n",
    "set_random_seed(2)\n",
    "train_size, epochs = X_train.shape[0], 10\n",
    "hist = model.fit_generator(image_generator_samples, steps_per_epoch=2*train_size//epochs,\n",
    "                           validation_data=(X_test, y_test), epochs=epochs, shuffle=True,\n",
    "                           callbacks=[checkpoint, early_stop])\n",
    "\n",
    "model.save_weights('models/weights_densenet201_2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet Model 3 (Random Seed = 1, considering class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'models/weights-{epoch:02d}-{val_loss:.3f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')\n",
    "\n",
    "model = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                           num_classes=len(set(labels_train_encoded)),\n",
    "                           percent_layers_freeze=0.1)\n",
    "\n",
    "batch_size = 32\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=.1,\n",
    "                               height_shift_range=.1,\n",
    "                               shear_range=0.5,\n",
    "                               zoom_range=(0.9, 1.1),\n",
    "                               fill_mode='constant',\n",
    "                               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5072/5072 [==============================] - 1583s 312ms/step - loss: 7.1346 - acc: 0.1885 - val_loss: 4.7227 - val_acc: 0.5752\n",
      "Epoch 2/10\n",
      "5072/5072 [==============================] - 1553s 306ms/step - loss: 6.5429 - acc: 0.1893 - val_loss: 4.3267 - val_acc: 0.5752\n",
      "Epoch 3/10\n",
      "5072/5072 [==============================] - 1545s 305ms/step - loss: 6.3507 - acc: 0.1901 - val_loss: 4.2276 - val_acc: 0.5759\n",
      "Epoch 4/10\n",
      "5072/5072 [==============================] - 1531s 302ms/step - loss: 6.2705 - acc: 0.1914 - val_loss: 4.2252 - val_acc: 0.5753\n",
      "Epoch 5/10\n",
      "5072/5072 [==============================] - 1575s 311ms/step - loss: 6.2239 - acc: 0.1911 - val_loss: 4.4160 - val_acc: 0.5749\n",
      "Epoch 6/10\n",
      "5072/5072 [==============================] - 1575s 311ms/step - loss: 6.1885 - acc: 0.1913 - val_loss: 4.1757 - val_acc: 0.5760\n",
      "Epoch 7/10\n",
      "5072/5072 [==============================] - 1577s 311ms/step - loss: 6.1608 - acc: 0.1920 - val_loss: 4.2577 - val_acc: 0.5757\n",
      "Epoch 8/10\n",
      "5072/5072 [==============================] - 1572s 310ms/step - loss: 6.1350 - acc: 0.1920 - val_loss: 4.2464 - val_acc: 0.5745\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_bootstrapper(data_train, labels_train_encoded,\n",
    "                                                           bootstrapper_size=sample_size,\n",
    "                                                           class_imbalance=True, random_state=1)\n",
    "    \n",
    "X_train = densenet201_preprocess(X_train)\n",
    "X_test = densenet201_preprocess(X_test)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "image_generator_samples = image_gen.flow(X_train, y_train, batch_size=batch_size, seed=1)\n",
    "    \n",
    "np.random.seed(1)\n",
    "set_random_seed(1)\n",
    "train_size, epochs = X_train.shape[0], 10\n",
    "hist = model.fit_generator(image_generator_samples, steps_per_epoch=2*train_size//epochs,\n",
    "                           validation_data=(X_test, y_test), epochs=epochs, shuffle=True,\n",
    "                           callbacks=[checkpoint, early_stop])\n",
    "\n",
    "model.save_weights('models/weights_densenet201_3.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet Model 4 (Random Seed = 2, considering class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'models/weights-{epoch:02d}-{val_loss:.3f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stop = EarlyStopping(patience=2, monitor='val_loss')\n",
    "\n",
    "model = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                           num_classes=len(set(labels_train_encoded)),\n",
    "                           percent_layers_freeze=0.1)\n",
    "\n",
    "batch_size = 32\n",
    "image_gen = ImageDataGenerator(rotation_range=20,\n",
    "                               width_shift_range=.1,\n",
    "                               height_shift_range=.1,\n",
    "                               shear_range=0.5,\n",
    "                               zoom_range=(0.9, 1.1),\n",
    "                               fill_mode='constant',\n",
    "                               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5072/5072 [==============================] - 1606s 317ms/step - loss: 7.1278 - acc: 0.1882 - val_loss: 4.7859 - val_acc: 0.5702\n",
      "Epoch 2/10\n",
      "5072/5072 [==============================] - 1586s 313ms/step - loss: 6.5771 - acc: 0.1893 - val_loss: 4.5678 - val_acc: 0.5702\n",
      "Epoch 3/10\n",
      "5072/5072 [==============================] - 1588s 313ms/step - loss: 6.4106 - acc: 0.1900 - val_loss: 4.4918 - val_acc: 0.5700\n",
      "Epoch 4/10\n",
      "5072/5072 [==============================] - 1584s 312ms/step - loss: 6.3385 - acc: 0.1905 - val_loss: 4.5803 - val_acc: 0.5697\n",
      "Epoch 5/10\n",
      "5072/5072 [==============================] - 1587s 313ms/step - loss: 6.2852 - acc: 0.1914 - val_loss: 4.4046 - val_acc: 0.5703\n",
      "Epoch 6/10\n",
      "5072/5072 [==============================] - 1584s 312ms/step - loss: 6.2574 - acc: 0.1916 - val_loss: 4.6082 - val_acc: 0.5696\n",
      "Epoch 7/10\n",
      "5072/5072 [==============================] - 1584s 312ms/step - loss: 6.2275 - acc: 0.1916 - val_loss: 4.4326 - val_acc: 0.5644\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_bootstrapper(data_train, labels_train_encoded,\n",
    "                                                           bootstrapper_size=sample_size,\n",
    "                                                           class_imbalance=True, random_state=2)\n",
    "    \n",
    "X_train = densenet201_preprocess(X_train)\n",
    "X_test = densenet201_preprocess(X_test)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "image_generator_samples = image_gen.flow(X_train, y_train, batch_size=batch_size, seed=2)\n",
    "    \n",
    "np.random.seed(2)\n",
    "set_random_seed(2)\n",
    "train_size, epochs = X_train.shape[0], 10\n",
    "hist = model.fit_generator(image_generator_samples, steps_per_epoch=2*train_size//epochs,\n",
    "                           validation_data=(X_test, y_test), epochs=epochs, shuffle=True,\n",
    "                           callbacks=[checkpoint, early_stop])\n",
    "\n",
    "model.save_weights('models/weights_densenet201_4.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
