{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble sum consisting of ResNet and DenseNet models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input as resnet50_preprocess\n",
    "from keras.applications.densenet import DenseNet201, preprocess_input as densenet201_preprocess\n",
    "\n",
    "from src.model_api import getPretrainedModel\n",
    "from src.prediction import array_filter, array_to_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of labels_train: 25361\n",
      "Shape of data_test: (7960, 224, 224, 3)\n",
      "Length of filename_test: 7960\n"
     ]
    }
   ],
   "source": [
    "with open('data/derived/labels_train.pickle', 'rb') as file:\n",
    "    labels_train = pickle.load(file)\n",
    "with open('data/derived/data_test.pickle', 'rb') as file:\n",
    "    data_test = pickle.load(file)\n",
    "with open('data/derived/test_file_names.pickle', 'rb') as file:\n",
    "    filenames_test = pickle.load(file)\n",
    "print('Length of labels_train:', len(labels_train))\n",
    "print('Shape of data_test:', data_test.shape)\n",
    "print('Length of filename_test:', len(filenames_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to integers for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['w_025911c', 'new_whale', 'new_whale', 'new_whale', 'new_whale']\n",
      "Encoded labels: [44  0  0  0  0]\n",
      "Label encoder classes: ['new_whale' 'w_0003639' 'w_0003c59' 'w_0027efa' 'w_00289b1']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "print('Original labels: {}'.format(labels_train[:5]))\n",
    "print('Encoded labels: {}'.format(labels_train_encoded[:5]))\n",
    "print('Label encoder classes: {}'.format(label_encoder.classes_[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sample size and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 25361\n",
      "Number of clases: 5005\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(labels_train_encoded)\n",
    "num_classes = len(set(labels_train_encoded))\n",
    "print('Sample size:', sample_size)\n",
    "print('Number of clases:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model_1 = getPretrainedModel(ResNet50(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                      num_classes=len(set(labels_train_encoded)),\n",
    "                                      percent_layers_freeze=0.1)\n",
    "resnet50_model_2 = getPretrainedModel(ResNet50(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                      num_classes=len(set(labels_train_encoded)),\n",
    "                                      percent_layers_freeze=0.1)\n",
    "resnet50_model_3 = getPretrainedModel(ResNet50(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                      num_classes=len(set(labels_train_encoded)),\n",
    "                                      percent_layers_freeze=0.1)\n",
    "resnet50_model_4 = getPretrainedModel(ResNet50(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                      num_classes=len(set(labels_train_encoded)),\n",
    "                                      percent_layers_freeze=0.1)\n",
    "densenet201_model_1 = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                         num_classes=len(set(labels_train_encoded)),\n",
    "                                         percent_layers_freeze=0.1)\n",
    "densenet201_model_2 = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                         num_classes=len(set(labels_train_encoded)),\n",
    "                                         percent_layers_freeze=0.1)\n",
    "densenet201_model_3 = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                         num_classes=len(set(labels_train_encoded)),\n",
    "                                         percent_layers_freeze=0.1)\n",
    "densenet201_model_4 = getPretrainedModel(DenseNet201(include_top=False, weights='imagenet', pooling='max'),\n",
    "                                         num_classes=len(set(labels_train_encoded)),\n",
    "                                         percent_layers_freeze=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model_1.load_weights('models/weights_resnet50_1.hdf5')\n",
    "resnet50_model_2.load_weights('models/weights_resnet50_2.hdf5')\n",
    "resnet50_model_3.load_weights('models/weights_resnet50_3.hdf5')\n",
    "resnet50_model_4.load_weights('models/weights_resnet50_4.hdf5')\n",
    "densenet201_model_1.load_weights('models/weights_densenet201_1.hdf5')\n",
    "densenet201_model_2.load_weights('models/weights_densenet201_2.hdf5')\n",
    "densenet201_model_3.load_weights('models/weights_densenet201_3.hdf5')\n",
    "densenet201_model_4.load_weights('models/weights_densenet201_4.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble v1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All model results having same weightage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_preds_1 = resnet50_model_1.predict(resnet50_preprocess(data_test))\n",
    "resnet50_preds_2 = resnet50_model_2.predict(resnet50_preprocess(data_test))\n",
    "resnet50_preds_3 = resnet50_model_3.predict(resnet50_preprocess(data_test))\n",
    "resnet50_preds_4 = resnet50_model_4.predict(resnet50_preprocess(data_test))\n",
    "densenet201_preds_1 = densenet201_model_1.predict(densenet201_preprocess(data_test))\n",
    "densenet201_preds_2 = densenet201_model_2.predict(densenet201_preprocess(data_test))\n",
    "densenet201_preds_3 = densenet201_model_3.predict(densenet201_preprocess(data_test))\n",
    "densenet201_preds_4 = densenet201_model_4.predict(densenet201_preprocess(data_test))\n",
    "overall_preds = resnet50_preds_1 + resnet50_preds_2 + resnet50_preds_3 + resnet50_preds_4 +\\\n",
    "densenet201_preds_1 + densenet201_preds_2 + densenet201_preds_3 + densenet201_preds_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain labels with top 5 softmax values for each array row and concatenate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_indices = np.apply_along_axis(array_filter, arr=overall_preds, axis=1, n_top=5, labels=label_encoder.classes_)\n",
    "predictions_array = np.apply_along_axis(array_to_string, arr=top5_indices, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission DataFrame and export as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  c303faac6.jpg  new_whale w_17b0d3a w_789c969 w_67a9841 w_a9304b9\n",
      "1  96c2b7290.jpg  new_whale w_af367c3 w_8c25681 w_6822dbc w_f765256\n",
      "2  69f6cd44f.jpg  new_whale w_23a388d w_d405854 w_5773c71 w_03670aa\n",
      "3  a965dea33.jpg  new_whale w_1f0cf0a w_3de579a w_985d205 w_cd4cb49\n",
      "4  9a225e056.jpg  new_whale w_5a2634c w_700ebb4 w_0a155b9 w_23a388d\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'Image': filenames_test, 'Id': predictions_array})\n",
    "submission_df.to_csv('submission_v1.csv', index=False)\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble v1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models weighted by accuracy score during training and validation phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_preds_1 = resnet50_model_1.predict(resnet50_preprocess(data_test))\n",
    "resnet50_preds_2 = resnet50_model_2.predict(resnet50_preprocess(data_test))\n",
    "resnet50_preds_3 = resnet50_model_3.predict(resnet50_preprocess(data_test))\n",
    "resnet50_preds_4 = resnet50_model_4.predict(resnet50_preprocess(data_test))\n",
    "densenet201_preds_1 = densenet201_model_1.predict(densenet201_preprocess(data_test))\n",
    "densenet201_preds_2 = densenet201_model_2.predict(densenet201_preprocess(data_test))\n",
    "densenet201_preds_3 = densenet201_model_3.predict(densenet201_preprocess(data_test))\n",
    "densenet201_preds_4 = densenet201_model_4.predict(densenet201_preprocess(data_test))\n",
    "overall_preds = 0.38*resnet50_preds_1 + 0.38*resnet50_preds_2 + 0.58*resnet50_preds_3 + 0.57*resnet50_preds_4 +\\\n",
    "0.38*densenet201_preds_1 + 0.38*densenet201_preds_2 + 0.58*densenet201_preds_3 + 0.57*densenet201_preds_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain labels with top 5 softmax values for each array row and concatenate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_indices = np.apply_along_axis(array_filter, arr=overall_preds, axis=1, n_top=5, labels=label_encoder.classes_)\n",
    "predictions_array = np.apply_along_axis(array_to_string, arr=top5_indices, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission DataFrame and export as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  c303faac6.jpg  new_whale w_17b0d3a w_67a9841 w_a9304b9 w_789c969\n",
      "1  96c2b7290.jpg  new_whale w_af367c3 w_8c25681 w_6822dbc w_f765256\n",
      "2  69f6cd44f.jpg  new_whale w_d405854 w_23a388d w_5773c71 w_fd3e556\n",
      "3  a965dea33.jpg  new_whale w_1f0cf0a w_cd4cb49 w_3de579a w_343f088\n",
      "4  9a225e056.jpg  new_whale w_5a2634c w_700ebb4 w_0a155b9 w_17b0d3a\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'Image': filenames_test, 'Id': predictions_array})\n",
    "submission_df.to_csv('submission_v2.csv', index=False)\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score: 0.286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
